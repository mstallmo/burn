use crate::{
    data::{ {{context.model_name}}Batch, {{context.model_name}}Batcher },
    model::{Model, ModelConfig},
};
use burn::{
    prelude::*,
    tensor::backend::AutodiffBackend,
    train::{
        ClassificationOutput, TrainOutput, TrainStep, ValidStep,
    },
};


impl<B: Backend> Model<B> {
    pub fn forward_classification(
        &self,
    ) -> ClassificationOutput<B> {
        todo!("Implement forward_classification...");
    }
}

impl<B: AutodiffBackend> TrainStep<{{context.model_name}}Batch<B>, ClassificationOutput<B>> for Model<B> {
    fn step(&self, batch: {{context.model_name}}Batch<B>) -> TrainOutput<ClassificationOutput<B>> {
        todo!("Implement train step...");
    }
}

impl<B: Backend> ValidStep<{{context.model_name}}Batch<B>, ClassificationOutput<B>> for Model<B> {
    fn step(&self, batch: {{context.model_name}}Batch<B>) -> ClassificationOutput<B> {
        todo!("Implement train step...");
    }
}

#[derive(Config)]
pub struct TrainingConfig {
    pub model: ModelConfig,
    // Add optimizer (e.x. pub optimizer: AdamConfig),
    #[config(default = 10)]
    pub num_epochs: usize,
    #[config(default = 64)]
    pub batch_size: usize,
    #[config(default = 4)]
    pub num_workers: usize,
    #[config(default = 42)]
    pub seed: u64,
    #[config(default = 1.0e-4)]
    pub learning_rate: f64,
}

fn create_artifact_dir(artifact_dir: &str) {
    std::fs::remove_dir_all(artifact_dir).ok();
    std::fs::create_dir_all(artifact_dir).ok();
}

pub fn train<B: AutodiffBackend>(artifact_dir: &str, config: TrainingConfig, device: B::Device) {
    create_artifact_dir(artifact_dir);
    config
        .save(format!("{artifact_dir}/config.json"))
        .expect("Config should be saved successfully");

    B::seed(config.seed);

    let _batcher = {{context.model_name}}Batcher::default();

    todo!("Implement model training...");
}
